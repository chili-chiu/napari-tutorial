{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb003a9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial uses napari 0.4.11.<br>\n",
    "Inspired by tutorials > single cell tracking with napari.\n",
    "\n",
    "Dataset :<br>\n",
    "[Chinese Hamster Ovarian (CHO) nuclei overexpressing GFP-PCNA from cell tracking challenge](http://data.celltrackingchallenge.net/training-datasets/Fluo-N3DH-CHO.zip).<br> \n",
    "3D time-lapse (xyzct = 512x443x5x1x92), ~100 MB<br>\n",
    "Voxel size (microns, xyz): 0.202 x 0.202 x 1.0<br>\n",
    "Time step (min): 9.5\n",
    "\n",
    "Analysis goals:<br> \n",
    "(1) Measure cell movement over time.<br>\n",
    "(2) Measure cell area change over time.<br>\n",
    "\n",
    "Tutorial goals:<br>\n",
    "(1) Use napari + Python libraries to perform common image analysis from end to end.<br>\n",
    "(2) Note napari viewer GUI/API function availability at varioius steps.  \n",
    "\n",
    "Steps:\n",
    "- Load timelapse image (celltracking)\n",
    "- Get image dimension and display with correct axes\n",
    "- Smooth the image using Gaussian filter\n",
    "<br><br>\n",
    "- Object detection: points\n",
    "- Tracking points\n",
    "- Filter tracks by track length\n",
    "- Calculate instant speed\n",
    "<br><br>\n",
    "- Object detection: labels\n",
    "- Labels to Points for tracking\n",
    "- Save track results\n",
    "\n",
    "<font color=red> RED: links to add<br> </font>\n",
    "<font color=blue> BLUE: GUI availability in viewer </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from napari.utils import nbscreenshot\n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d7c35",
   "metadata": {},
   "source": [
    "## Load timelapse image\n",
    "\n",
    "This tutorial only uses files in Fluo-N3DH-CHO > 01 folder.<br>\n",
    "92 tif files are in the folder (t000.tif, ..., t091.tif), each represents a 3D image acquired at a given time point.\n",
    "\n",
    "<font color=blue> \n",
    "    GUI option 1: File > Open Files as Stack...> select all tif files in the folder.<br>\n",
    "    GUI option 2: File > Open Folder > select 01 folder.<br>\n",
    "</font>\n",
    "<font color=red>link: supported file format and plugins</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642db2f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "\n",
    "#modify the file path to match file location\n",
    "img_path = '/Users/cchiu/Desktop/images/Fluo-N3DH-CHO/01/'\n",
    "\n",
    "#get the total number of files in the folder\n",
    "num_files = len(os.listdir(img_path))\n",
    "print('number of tif files: ',num_files)\n",
    "\n",
    "def load_timelapse(idx: int):\n",
    "    filename = os.path.join(img_path, f't{idx:0>3}.tif')\n",
    "    return imread(filename)\n",
    "\n",
    "#load all tif files as single array\n",
    "stack = np.asarray([load_timelapse(i) for i in range(num_files)])\n",
    "print('stack size: ',stack.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe916a",
   "metadata": {},
   "source": [
    "## Get image dimension and display with correct axes\n",
    "The original shape is (92, 5, 443, 512), corresponding to axes order TZYX.<br>\n",
    "napari takes the axes order TZYX with C represented as separate image layers, so no additional steps are needed.<br> \n",
    "If the image stack order is not correct, use np.transpose to get the dimensions in the right order, then split each channel as one image layer for easier display/analysis.<br>\n",
    "\n",
    "For the remaining tutorial, only the first 10 time points will be used for faster calculation.<br>\n",
    "\n",
    "[<font color=blue>issue 2917</font>](https://github.com/napari/napari/issues/2917),\n",
    "[<font color=blue>issue 906</font>](https://github.com/napari/napari/issues/906)\n",
    "\n",
    "<font color=blue>\n",
    "    A 2D timelapse and a 3D image cannot be differentiated due to the lack of axis names. This can make downstream analysis ambiguous - and error prone - see the segmentation part. <br>     \n",
    "    Changing axes is challenging to do in GUI<br>\n",
    "    No simple way to crop/select certain dimensions in GUI.<br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load only the first 10 time points and only uses the first z slice\n",
    "small_stack = stack[0:10,0,:,:]\n",
    "\n",
    "viewer = napari.view_image(small_stack, name=\"cells\")\n",
    "print(small_stack.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3faf3f8",
   "metadata": {},
   "source": [
    "## Smooth the image using Gaussian filter\n",
    "\n",
    "Smoothed image (and other pre-processing steps) can simplify segmentation/object detection by removing unwanted signal variations.<br>\n",
    "\n",
    "Use skimage.filters.gaussian to perform Gaussian smoothing. <br>\n",
    "Because we only want to smooth along xy dimension, t sigma is set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "smoothed = skimage.filters.gaussian(small_stack, sigma=[0,8,8])\n",
    "viewer.add_image(smoothed, name='smoothed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdab474",
   "metadata": {},
   "source": [
    "## Object detection: Points\n",
    "\n",
    "Some analyses only require tracking the centroid of the objects, i.e. speed, directionality, etc.<br>\n",
    "\n",
    "<font color=blue>napari-stracking plugin > S Detector Dog/Doh/Log</font><br>\n",
    "<font color=red>Points layer tutorial</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac88eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find points per time point, and store the result as [time index, y coordinate, x coordinate]\n",
    "def peaks(time_point):\n",
    "    blobs = skimage.feature.blob_log(smoothed[time_point,:,:],min_sigma=5,threshold=0.08,overlap=0.4)\n",
    "    points = np.empty(3)\n",
    "    for blob in blobs:\n",
    "        point = [time_point,blob[0],blob[1]]\n",
    "        points = np.vstack([points,point])\n",
    "    return points[1:]\n",
    "\n",
    "#detect points for all time points\n",
    "points_all = np.empty(3)\n",
    "for t in range(viewer.layers['cells'].data.shape[0]):\n",
    "    points = peaks(t)\n",
    "    points_all = np.vstack([points_all,points])\n",
    "\n",
    "#add points as points layer\n",
    "viewer.add_points(points_all[1:], size=10, name='cell_points')\n",
    "\n",
    "#a better way than adding np.empty?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec3031",
   "metadata": {},
   "source": [
    "## Tracking points\n",
    "\n",
    "Track layer saves array (track_id, T, Z, Y, X).<br>\n",
    "Directly use plugin for track detection for simplicity.<br>\n",
    "\n",
    "<font color=blue>napari-stracking plugin > S Linker Shortest Path</font><br>\n",
    "<font color=red>tracks layer tutorial</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use napari-stracking plugin > S Linker Shortest Path for tracking\n",
    "#Detections layer = cell_points\n",
    "#Max distance = 30\n",
    "#Gap = 1\n",
    "\n",
    "#print(viewer.layers[-1].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c22730d",
   "metadata": {},
   "source": [
    "## Filter tracks by track length\n",
    "\n",
    "Two main types of track related statistics:<br>\n",
    "(1) Whole track statistics (track_stat) - track duration, avg. speed, etc.<br>\n",
    "(2) Per time point statistics (point_stat) - instant speed, MSD, etc.<br>\n",
    "\n",
    "To avoid redundancy, create two separate dataframes to store the above, with shared column 'track_ID'.<br>\n",
    "This approach however requires update on both dataframes when filtering/updating one of them.<br>\n",
    "\n",
    "Additional challenge: if we want to also update points layer and only keeps the points that only reflect the filtered result, it becomes even messier...<br>\n",
    "Another common scenario: After tracking points, user may want to adjust points, and the change also needs to be propagated to track layer and the corresponding stats.<br>\n",
    "\n",
    "<font color=blue> No known GUI/plugins </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ce001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#create point_stat from tracks layer\n",
    "point_stat = pd.DataFrame(viewer.layers[-1].data, columns = ['track_ID','time','coor_y','coor_x'])\n",
    "point_stat['track_ID'] = point_stat['track_ID'].astype(int)\n",
    "\n",
    "#create track_stat with unique track_ID, and add track_length stats\n",
    "track_length = point_stat['track_ID'].value_counts()\n",
    "track_stat = pd.DataFrame(track_length)\n",
    "track_stat = track_stat.reset_index()\n",
    "track_stat.columns = ['track_ID', 'track_length'] \n",
    "\n",
    "#print('track_stat:')\n",
    "#display(track_stat)\n",
    "\n",
    "#only keeps tracks with track_length > 6\n",
    "#filter both track_stat and point_stat\n",
    "min_length = 6\n",
    "\n",
    "f_track_stat = track_stat[track_stat['track_length'] > min_length].dropna()\n",
    "print('f_track_stat:')\n",
    "display(f_track_stat)\n",
    "\n",
    "f_point_stat = point_stat[point_stat['track_ID'].isin(f_track_stat.track_ID.tolist())]\n",
    "display(f_point_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b2d47",
   "metadata": {},
   "source": [
    "## Calculate instant speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79856b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def speed(y1,y2,x1,x2):\n",
    "    s = math.sqrt((y2-y1)**2+(x2-x1)**2)\n",
    "    if np.isnan(s):\n",
    "        return 0\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "#add new columns coor_yp and coor_xp for the coordinates from the previous time point. \n",
    "#For time point 0, coor_yp = coor_y, coor_xp = coor_x\n",
    "\n",
    "f_point_stat['coor_yp']=f_point_stat.shift(periods=1)['coor_y']\n",
    "f_point_stat['coor_xp']=f_point_stat.shift(periods=1)['coor_x']\n",
    "\n",
    "#calculate instant speed for all time points\n",
    "for index, row in f_point_stat.iterrows():\n",
    "    new_speed = speed(row['coor_y'],row['coor_yp'],row['coor_x'],row['coor_xp'])\n",
    "    f_point_stat.at[index, 'speed'] = new_speed\n",
    "\n",
    "display(f_point_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c273a",
   "metadata": {},
   "source": [
    "## Object detection: Labels\n",
    "\n",
    "Some analyses require capturing the overall volume of objects, i.e. morphology change, intensity fluctuation, etc.<br>\n",
    "\n",
    "Use simple intensity threshold-based segmentation on smoothed image.<br> \n",
    "\n",
    "WARNING: Convert to label needs to be applied on a per time point basis, otherwise objects overlapping in time will be assigned the same label index (i.e. being treated as 3D image). This axis ambiguity can contribute to segmentation plugins not working properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04654168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot intensity distribution\n",
    "from matplotlib.pyplot import hist\n",
    "_ = hist(smoothed.flatten(),bins=50,log=True)\n",
    "\n",
    "#binarize the image using intensity = 0.1\n",
    "threshold = 0.1\n",
    "cutoff_cell = smoothed > threshold\n",
    "viewer.add_image(cutoff_cell, name='cutoff cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07f8a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "#create connectivity structure so that objects are not considered connected along time dimension.\n",
    "s = scipy.ndimage.morphology.generate_binary_structure(3,1)\n",
    "s[0] = False\n",
    "s[2] = False\n",
    "\n",
    "#turn binary image into labels layer\n",
    "seg_cell,num_objs = scipy.ndimage.label(cutoff_cell, structure=s)\n",
    "viewer.add_labels(seg_cell, name='cell seg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c421f3",
   "metadata": {},
   "source": [
    "## Labels to Points for tracking\n",
    "\n",
    "Same considerations as for Points, multiple dataframes may be needed to hold the information.<br>\n",
    "Once Labels coordinates are converted into points, the same process of tracking can be applied.\n",
    "\n",
    "<font color=blue> Would be nice to have tracking directly on labels and bypass adding additional layers :)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract object coordinates for tracking\n",
    "from skimage.measure import regionprops_table\n",
    "\n",
    "p = ['label', 'centroid','area'] #additional properties can be added here\n",
    "obj_stat = pd.DataFrame(regionprops_table(seg_cell,intensity_image=small_stack,properties=p))\n",
    "obj_stat = obj_stat.rename(columns={\"centroid-0\": \"time\", \"centroid-1\": \"coor_y\",\"centroid-2\": \"coor_x\"})\n",
    "display(obj_stat)\n",
    "label_point = obj_stat[['time','coor_y','coor_x']].to_numpy()\n",
    "viewer.add_points(label_point, size=10, name='label_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4330f4c",
   "metadata": {},
   "source": [
    "## Save track results\n",
    "\n",
    "Since tracking analyses require information from several layer sources, save all layers may be necessary.\n",
    "\n",
    "<font color=blue> File > Save All Layers... </font> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
