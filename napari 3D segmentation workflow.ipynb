{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb003a9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial uses napari 0.4.11. \n",
    "\n",
    "Dataset (flyLight):<br>\n",
    "[Image file download link](https://drive.google.com/file/d/1CijVxebE4a-mMMvkB7HxuVdFHvO378Eg/view?usp=sharing).<br> \n",
    "Original file downloaded from https://www.janelia.org/project-team/flylight<br>\n",
    "3D, 4 channel\n",
    "\n",
    "Analysis goal:<br> \n",
    "Measure the length of main neuron from ch2\n",
    "\n",
    "Tutorial goals:<br>\n",
    "(1) Use napari + Python libraries to perform common image analysis from end to end.<br>\n",
    "(2) Note napari viewer GUI function availability at varioius steps.  \n",
    "\n",
    "Steps:\n",
    "- Load 3D multi-channel image (flyLight)\n",
    "- Get image dimension and display with correct axes\n",
    "- Adjust image display\n",
    "- Crop and downsample image\n",
    "- Denoising by median filter\n",
    "- Segmentation by simple threshold\n",
    "- Clean up segmentation result\n",
    "- Set pixel size\n",
    "- Save segmented result: labels and properties\n",
    "\n",
    "<font color=red> RED: links to add<br> </font>\n",
    "<font color=blue> BLUE: GUI availability in viewer </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from napari.utils import nbscreenshot\n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d7c35",
   "metadata": {},
   "source": [
    "## Load image\n",
    "napari natively supports tiff (and ???) as input image file format.<br>\n",
    "Additional input file formats may be supported by plugins.<br>\n",
    "\n",
    "<font color=blue> GUI has several file open options (drag and drop, File > Open File) <br></font>\n",
    "<font color=red>link: supported file format and plugins</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642db2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "#modify the file path to match file location\n",
    "flyLight = imread('/Users/cchiu/Desktop/images/flyLight_aligned_stack.tif')\n",
    "print(\"original file dimension: \", flyLight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe916a",
   "metadata": {},
   "source": [
    "## Get image dimension and display with correct axes\n",
    "The original shape is (219, 4, 1119, 573), corresponding to axes order ZCYX.<br>\n",
    "napari takes the axes order TZYX with C represented as separate image layers.<br> \n",
    "To display the image correctly, use np.transpose to get the dimensions in the right order, then split each channel as one image layer for easier display/analysis.<br>\n",
    "<font color=blue>\n",
    "    Changing axes is challenging to do in GUI<br>\n",
    "    Channel name and ndisplay can be changed in GUI\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b862f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#chanage the axes to match CZYX\n",
    "flyLight_dim_correct = np.transpose(flyLight, (1,0,2,3))\n",
    "\n",
    "#load multi-channel image in one line, with channel name, and display in 3D\n",
    "viewer = napari.view_image(flyLight_dim_correct, channel_axis=0, name=[\"ch1\",\"ch2\",\"ch3\",\"ch4\"], ndisplay=3)\n",
    "\n",
    "#equivalent to\n",
    "#for i in range(flyLight_dim_correct.shape[0]):\n",
    "#    viewer.add_image(np.squeeze(flyLight_dim_correct[i,:,:,:]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f10e2",
   "metadata": {},
   "source": [
    "## Adjust image display\n",
    "\n",
    "<font color=blue> Both API and GUI have flexible image display control. <blue>    \n",
    "<font color=red>Link: API and GUI display reference</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change ch1 color from cyan to gray \n",
    "viewer.layers['ch1'].colormap = 'gray'\n",
    "#change ch4 opacity to 0.6\n",
    "viewer.layers['ch4'].opacity = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df888142",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a86466",
   "metadata": {},
   "source": [
    "## Crop and downsample image\n",
    "<br>\n",
    "<font color=blue>\n",
    "    No crop and downsample funtions in GUI.<br>\n",
    "    Cursor coordinate (in pixel) is displayed in GUI, which helps with determining ROI.   \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original image flyLight_dim_correct has CZYX size (4,219,1119,573)\n",
    "print(\"original image size: \", flyLight_dim_correct.shape)\n",
    "\n",
    "#crop x and y 20 pixels from each side, and downsample 2x along z\n",
    "flyLight_crop = flyLight_dim_correct[:,::2,20:1098,20:552]\n",
    "\n",
    "#remove the original image layers\n",
    "viewer.layers.select_all()\n",
    "viewer.layers.remove_selected()\n",
    "\n",
    "#load cropped image\n",
    "viewer.add_image(flyLight_crop, channel_axis=0, name=[\"ch1\",\"ch2\",\"ch3\",\"ch4\"])\n",
    "\n",
    "#new image ZYX size\n",
    "print(\"new image size: \", viewer.layers[0].data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4ddbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8a8a4d",
   "metadata": {},
   "source": [
    "## Denoising by median filter\n",
    "\n",
    "To reduce noise in channel 2:<br> \n",
    "(1) Apply median filter to remove salt-and-pepper noise<br>\n",
    "(2) Create a new image layer for the filtered image\n",
    "\n",
    "<font color=blue>Available plugin: pyclesperanto<br></font>\n",
    "<font color=red>link: magicgui to make interactive plot<br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f64101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "#median filter\n",
    "filtered_ch2 = skimage.filters.median(viewer.layers[\"ch2\"].data)\n",
    "viewer.add_image(filtered_ch2, name='filtered ch2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8238bb3b",
   "metadata": {},
   "source": [
    "## Segmentation by simple threshold\n",
    "\n",
    "(1) Use intensity histogram to determine the appropriate intensity threshold<br>\n",
    "(2) Use the intensity threshold to create a binarized image<br>\n",
    "(3) Convert the binarized image to label (i.e. segmented and represented as unique integer per object)<br>\n",
    "\n",
    "<br>\n",
    "<font color=blue>\n",
    "    No intensity histogram in GUI.<br>\n",
    "    Label supports manual annotation in GUI.<br>\n",
    "</font>\n",
    "<font color=red>link: segmentation plugins and labels layer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41001172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot intensity distribution in ch2\n",
    "from matplotlib.pyplot import hist\n",
    "hist(filtered_ch2.flatten(),bins=50,log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarize the image using intensity = 150\n",
    "threshold = 150\n",
    "cutoff_ch2 = filtered_ch2 > threshold\n",
    "viewer.add_image(cutoff_ch2, name='cutoff ch2')\n",
    "\n",
    "#turn binary image into label layer\n",
    "seg_ch2 = skimage.measure.label(cutoff_ch2)\n",
    "viewer.add_labels(seg_ch2, name='ch2 seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b88bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb84b3",
   "metadata": {},
   "source": [
    "## Clean up segmentation result\n",
    "(1) [not shown here] Use plugin segmentation (split/merge) to manually merge the neuron segments<br>\n",
    "(2) Remove small objects\n",
    "\n",
    "<font color=blue>\n",
    "    Label can be interactively modified in GUI.<br> \n",
    "    No object property GUI.<br></font>\n",
    "<font color=red>link: feature extraction plugins - as of now show the property table but no selection tool, and may have less option for 3D.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aea284",
   "metadata": {},
   "outputs": [],
   "source": [
    "props = skimage.measure.regionprops_table(seg_ch2, properties=['label','area'])\n",
    "\n",
    "import pandas as pd\n",
    "#object property (area) distribution\n",
    "data = pd.DataFrame(props)\n",
    "hist(data['area'],bins=10,log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012aef43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create new label layer with only larger objects\n",
    "bigger_obj_label = skimage.morphology.remove_small_objects(seg_ch2, min_size=1000)\n",
    "viewer.add_labels(bigger_obj_label,name='bigger objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec8e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only show the bigger object layer\n",
    "for layer in viewer.layers:\n",
    "    layer.visible = False\n",
    "viewer.layers['bigger objects'].visible = True\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c35ba0",
   "metadata": {},
   "source": [
    "## Set pixel size\n",
    "Default pixel size is set to (1,1,1) unless directly read from metadata.<br> \n",
    "Pixel size affects visualization scaling, remember to adjust the value if downsampled.<br>\n",
    "\n",
    "<font color=blue> \n",
    "    No GUI to specify pixel size and time interval.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set pixel size in um scale (z,y,x)\n",
    "pixel_size = np.array([2,1,1])\n",
    "\n",
    "for img_layer in viewer.layers:\n",
    "    img_layer.scale = pixel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f4c35",
   "metadata": {},
   "source": [
    "## Save segmented result\n",
    "Label layer export<br>\n",
    "Option 1: save as numpy .npy format - can be opened directly by viewer<br>\n",
    "Option 2: save as tiff - the export format when saved from GUI<br>\n",
    "*Note that properties (pixel size etc.) are not saved and need to be specified again when opening the saved file.\n",
    "\n",
    "Object property export<br>\n",
    "Option 1: save object properties as pickle<br>\n",
    "Option 2: save object properties as csv<br> \n",
    "\n",
    "<font color=blue>\n",
    "    GUI supports File > Save Layer.<br>\n",
    "    Feature extraction plugin provides csv export.<br>\n",
    "</font>\n",
    "<font color=red>link: label IO plugins<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36893da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save label layer in numpy .npy format \n",
    "import numpy\n",
    "numpy.save('FlyLight_label', bigger_obj_label)\n",
    "\n",
    "#save label layer in tiff format\n",
    "viewer.layers['bigger objects'].save('FlyLight_label.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b8a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save object properties (pnadas dataframe) as pickle\n",
    "data.to_pickle('flyLight_property.pkl')\n",
    "\n",
    "#save object properties as csv\n",
    "data.to_csv('flyLight_property.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
